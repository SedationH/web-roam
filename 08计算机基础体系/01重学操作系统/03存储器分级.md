## 为什么存储器要分级？

思考的原点： **需求**

任何设计都是为了满足需求的，设计需要结合现实约束，因此，要去明确两点

1. 我们的需求是什么
2. 有哪些现实约束



需求上来看，我们需要存储器速度快，体积小，存储空间大，能耗低，散热好，断电数据不会丢失，然而他们不可能同时满足，所以就开始**tradeoff**



**认知盲点**

光速很快，信号又在电子元器件上以光速传递，延迟应该很小 ❎

时钟信号是1GHz = 10^9Hz 的CPU，光速是3*10^8 

在一个时钟周期里，信号只能走0.3m，所以即使元件距离稍微远了一点，运行速度也会下降的比较明显



## 需求分解

因此，既然不能用一块存储器来解决所有的需求，那就把需求分级 -> 这个设计思路是所有缓存设计的原点



一种可行的方案，就是根据数据的使用频率使用不同的存储器：高频使用的数据，读写越快越好，因此用最贵的材料，放到离 CPU 最近的位置；使用频率越低的数据，我们放到离 CPU 越远的位置，用越便宜的材料。

具体来说，通常我们把存储器分成这么几个级别：

- 寄存器 半个CPU时钟周期

  > - 比如一条要在 4 个周期内完成的指令，除了读写寄存器，还需要解码指令、控制指令执行和计算。如果寄存器的速度太慢，那 4 个周期就可能无法完成这条指令了。

- L1-Cache 2～4

- L2-Cache 10～20

- L3-Cahce 20～60

- 内存 
  - 半导体硅 通过总线与CPU连接 200~300

- 硬盘/SSD
  - A *solid-state drive* (*SSD*) is a solid-state storage device that uses integrated circuit assemblies to store data persistently  2000~200000
  - 物理读写的太慢了 逐渐淘汰



前四个都集成在CPU中



## 读取数据

当CPU需要存储器中的某个数据的时候，从上至下依次搜索

现在出现了新的问题，如何设计搜索算法和存储数据结构

缓存说白了就是key : value

方案：

​	暴力逐个尝试 -> 哈希映射





## 指令预读

CPU执行内存中的指令，然而读写内存的速度在200～300CPU时钟周期，如何解决这个速度差异？

> 业务方面，开发RPC（In distributed computing, a remote procedure call is when a computer program causes a procedure to execute in a different address space, which is coded as if it were a normal procedure call, without the programmer explicitly coding the details for the remote interaction.）也会遇到一样问题，远程调用拖慢了整体的执行速度，如何处理？

解决方案：缓存

CPU预先读取几十条或者上百条指令到L1-缓存中

通常L1-缓存分为指令区和数据区，防止数据覆盖指令

只有L1-缓存需要协助处理指令预读



通过这样的缓存优化，操作系统的调度下，L1命中率（CPU在缓存中拿到所需数据的概率，与此相对的叫做穿透miss）80%， L1+L2+L3可达95%



因此，程序语言逐渐取消了让程序员操作寄存器的操作，因为在操作系统提供这样的缓存优化的背景下，多余的优化意义不大。